#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üõ†Ô∏è –ú–û–î–£–õ–¨ –£–¢–ò–õ–ò–¢
================
–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –≤–µ–±-—Å–∞–π—Ç–æ–≤

–ê–≤—Ç–æ—Ä: Senior Python Developer
–í–µ—Ä—Å–∏—è: 3.0.0
"""

import logging
import re
from urllib.parse import urlparse
import os
import sys
from datetime import datetime

def setup_logging(level=logging.INFO):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # –ò–º—è —Ñ–∞–π–ª–∞ –ª–æ–≥–∞ —Å –¥–∞—Ç–æ–π
    log_filename = os.path.join(log_dir, f"analyzer_{datetime.now().strftime('%Y%m%d')}.log")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Ñ–∞–π–ª–∞
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setLevel(level)
    file_handler.setFormatter(formatter)
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(formatter)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
    logger = logging.getLogger('WebsiteAnalyzer')
    logger.setLevel(level)
    
    # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    logger.handlers.clear()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    # –û—Ç–∫–ª—é—á–∞–µ–º propagation —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    logger.propagate = False
    
    logger.info("–°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    return logger

def validate_url(url: str) -> str:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL
    
    Args:
        url: URL –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        
    Returns:
        str: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π URL
        
    Raises:
        ValueError: –ï—Å–ª–∏ URL –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π
    """
    
    if not url or not isinstance(url, str):
        raise ValueError("URL –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    
    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã
    url = url.strip()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ö–µ–º—É –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    # –ü–∞—Ä—Å–∏–º URL
    try:
        parsed = urlparse(url)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        if not parsed.netloc:
            raise ValueError("–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π URL: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –¥–æ–º–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–µ–º—É
        if parsed.scheme not in ['http', 'https']:
            raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ HTTP –∏ HTTPS —Å—Ö–µ–º—ã")
        
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–º–µ–Ω–∞
        domain_pattern = re.compile(
            r'^[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?'
            r'(\.[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?)*$'
        )
        
        if not domain_pattern.match(parsed.netloc.split(':')[0]):
            raise ValueError("–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–æ–º–µ–Ω–∞")
        
        return url
        
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ URL: {e}")

def format_bytes(bytes_count: int) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –≤ –±–∞–π—Ç–∞—Ö –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥
    
    Args:
        bytes_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞–π—Ç
        
    Returns:
        str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
    """
    
    if bytes_count == 0:
        return "0 –ë"
    
    units = ['–ë', '–ö–ë', '–ú–ë', '–ì–ë', '–¢–ë']
    unit_index = 0
    size = float(bytes_count)
    
    while size >= 1024 and unit_index < len(units) - 1:
        size /= 1024
        unit_index += 1
    
    if unit_index == 0:
        return f"{int(size)} {units[unit_index]}"
    else:
        return f"{size:.1f} {units[unit_index]}"

def format_number(number: int) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Ç—ã—Å—è—á
    
    Args:
        number: –ß–∏—Å–ª–æ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ
    """
    
    return f"{number:,}".replace(',', ' ')

def clean_text(text: str, max_length: int = None) -> str:
    """
    –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        
    Returns:
        str: –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    
    if not text:
        return ""
    
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    text = re.sub(r'\s+', ' ', text.strip())
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    if max_length and len(text) > max_length:
        text = text[:max_length-3] + "..."
    
    return text

def extract_domain(url: str) -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–º–µ–Ω–∞ –∏–∑ URL
    
    Args:
        url: URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
    Returns:
        str: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
    """
    
    try:
        parsed = urlparse(url)
        return parsed.netloc.lower()
    except:
        return ""

def is_internal_url(url: str, base_domain: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º
    
    Args:
        url: URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        base_domain: –ë–∞–∑–æ–≤—ã–π –¥–æ–º–µ–Ω —Å–∞–π—Ç–∞
        
    Returns:
        bool: True –µ—Å–ª–∏ URL –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π
    """
    
    try:
        url_domain = extract_domain(url)
        return url_domain == base_domain.lower() or not url_domain
    except:
        return False

def safe_filename(filename: str) -> str:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    
    Args:
        filename: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        
    Returns:
        str: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    """
    
    # –£–¥–∞–ª—è–µ–º –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    safe_chars = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    if len(safe_chars) > 200:
        safe_chars = safe_chars[:200]
    
    # –£–¥–∞–ª—è–µ–º —Ç–æ—á–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    safe_chars = safe_chars.strip('.')
    
    # –ï—Å–ª–∏ –∏–º—è –ø—É—Å—Ç–æ–µ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ
    if not safe_chars:
        safe_chars = f"file_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    return safe_chars

def get_file_extension(content_type: str) -> str:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø–æ MIME —Ç–∏–ø—É
    
    Args:
        content_type: MIME —Ç–∏–ø
        
    Returns:
        str: –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    """
    
    mime_extensions = {
        'text/html': '.html',
        'text/css': '.css',
        'text/javascript': '.js',
        'application/javascript': '.js',
        'application/json': '.json',
        'application/xml': '.xml',
        'text/xml': '.xml',
        'image/jpeg': '.jpg',
        'image/png': '.png',
        'image/gif': '.gif',
        'image/svg+xml': '.svg',
        'application/pdf': '.pdf',
        'text/plain': '.txt'
    }
    
    return mime_extensions.get(content_type.lower(), '')

def calculate_similarity(text1: str, text2: str) -> float:
    """
    –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤
    
    Args:
        text1: –ü–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç
        text2: –í—Ç–æ—Ä–æ–π —Ç–µ–∫—Å—Ç
        
    Returns:
        float: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –æ—Ç 0 –¥–æ 1
    """
    
    try:
        from difflib import SequenceMatcher
        return SequenceMatcher(None, text1, text2).ratio()
    except:
        return 0.0

def parse_robots_txt(robots_content: str) -> dict:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ robots.txt
    
    Args:
        robots_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ robots.txt
        
    Returns:
        dict: –†–∞—Å–øars–µ–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
    """
    
    rules = {
        'user_agents': {},
        'sitemaps': [],
        'crawl_delay': None
    }
    
    current_user_agent = None
    
    for line in robots_content.split('\n'):
        line = line.strip()
        
        if not line or line.startswith('#'):
            continue
        
        if ':' in line:
            key, value = line.split(':', 1)
            key = key.strip().lower()
            value = value.strip()
            
            if key == 'user-agent':
                current_user_agent = value
                if current_user_agent not in rules['user_agents']:
                    rules['user_agents'][current_user_agent] = {
                        'disallow': [],
                        'allow': []
                    }
            
            elif key == 'disallow' and current_user_agent:
                rules['user_agents'][current_user_agent]['disallow'].append(value)
            
            elif key == 'allow' and current_user_agent:
                rules['user_agents'][current_user_agent]['allow'].append(value)
            
            elif key == 'sitemap':
                rules['sitemaps'].append(value)
            
            elif key == 'crawl-delay':
                try:
                    rules['crawl_delay'] = float(value)
                except:
                    pass
    
    return rules

def generate_user_agents():
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö User-Agent —Å—Ç—Ä–æ–∫
    
    Returns:
        list: –°–ø–∏—Å–æ–∫ User-Agent —Å—Ç—Ä–æ–∫
    """
    
    return [
        # Chrome
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        
        # Firefox
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:89.0) Gecko/20100101 Firefox/89.0',
        'Mozilla/5.0 (X11; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0',
        
        # Safari
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15',
        
        # Edge
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59',
        
        # Opera
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 OPR/77.0.4054.172'
    ]

def check_dependencies():
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    
    Returns:
        dict: –°—Ç–∞—Ç—É—Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    """
    
    dependencies = {
        'requests': False,
        'beautifulsoup4': False,
        'fake_useragent': False,
        'selenium': False,
        'cloudscraper': False,
        'undetected_chromedriver': False
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å
    for dep in dependencies:
        try:
            if dep == 'beautifulsoup4':
                import bs4
            elif dep == 'fake_useragent':
                import fake_useragent
            elif dep == 'undetected_chromedriver':
                import undetected_chromedriver
            else:
                __import__(dep)
            dependencies[dep] = True
        except ImportError:
            dependencies[dep] = False
    
    return dependencies

def get_system_info():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ
    
    Returns:
        dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
    """
    
    import platform
    
    return {
        'platform': platform.platform(),
        'system': platform.system(),
        'release': platform.release(),
        'version': platform.version(),
        'machine': platform.machine(),
        'processor': platform.processor(),
        'python_version': platform.python_version(),
        'python_implementation': platform.python_implementation()
    }

def create_progress_callback(total_steps: int):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ callback —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    
    Args:
        total_steps: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
        
    Returns:
        function: Callback —Ñ—É–Ω–∫—Ü–∏—è
    """
    
    current_step = [0]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –∏–∑–º–µ–Ω—è–µ–º–æ—Å—Ç–∏
    
    def progress_callback(message: str = ""):
        current_step[0] += 1
        percentage = (current_step[0] / total_steps) * 100
        
        print(f"[{percentage:.1f}%] {message}")
        
        return {
            'current': current_step[0],
            'total': total_steps,
            'percentage': percentage,
            'message': message
        }
    
    return progress_callback

def error_handler(func):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
    
    Args:
        func: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–∫–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        function: –î–µ–∫–æ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    """
    
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger = logging.getLogger('WebsiteAnalyzer')
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ {func.__name__}: {e}")
            raise
    
    return wrapper

def retry_on_failure(max_attempts: int = 3, delay: float = 1.0):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –Ω–µ—É–¥–∞—á–µ
    
    Args:
        max_attempts: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
        
    Returns:
        function: –î–µ–∫–æ—Ä–∞—Ç–æ—Ä
    """
    
    def decorator(func):
        def wrapper(*args, **kwargs):
            import time
            
            last_exception = None
            
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_attempts - 1:
                        time.sleep(delay * (attempt + 1))  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
                    continue
            
            # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã, –ø–æ–¥–Ω–∏–º–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
            raise last_exception
        
        return wrapper
    return decorator

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
USER_AGENTS = generate_user_agents()

HTTP_STATUS_CODES = {
    200: "OK",
    301: "Moved Permanently", 
    302: "Found",
    403: "Forbidden",
    404: "Not Found",
    429: "Too Many Requests",
    500: "Internal Server Error",
    502: "Bad Gateway",
    503: "Service Unavailable",
    504: "Gateway Timeout"
}

COMMON_HEADERS = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ru,en-US;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate, br',
    'DNT': '1',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'none',
    'Cache-Control': 'max-age=0'
}

# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
__all__ = [
    'setup_logging',
    'validate_url', 
    'format_bytes',
    'format_number',
    'clean_text',
    'extract_domain',
    'is_internal_url',
    'safe_filename',
    'calculate_similarity',
    'check_dependencies',
    'get_system_info',
    'error_handler',
    'retry_on_failure',
    'USER_AGENTS',
    'HTTP_STATUS_CODES',
    'COMMON_HEADERS'
]